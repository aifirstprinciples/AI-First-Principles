
#AI First Principles
AI isn't coming for jobs, it's coming for the bureaucracy that makes work miserable. AI eliminates dysfunction only when you rebuild operations around its capabilities. Automating broken processes just scales dysfunction.

These principles guide people operationalizing AI. They emerged from watching systems fail, then understanding why.

**AI Inherits Human Patterns**  
AI learns from human-generated data, absorbing the bias, inconsistency, and contextual assumptions. This makes variation inevitable, not accidental. <u>*Variation is guaranteed. Constraints aren't optional.*</u>

**People Own Objectives**  
Every objective needs a human owner to ensure people remain accountable for outcomes. When AI causes harm, the human owner is accountable, not the algorithm. <u>*Name the Owner.*</u>

**Individuals Come First**  
AI industrializes manipulation by personalizing it at scale. Prioritize human autonomy, safety, and well-being above efficiency, profit, or convenience. What once required mass campaigns now operates at the individual level, faster than people can recognize or consent. <u>*Build systems that preserve human agency above all else.*</u>

**Deception Destroys Trust**  
AI that pretends to be human eliminates informed consent and creates false relationships. People cannot collaborate effectively with what they don't recognize as artificial. <u>*Make AI obvious, not hidden.*</u>

**AI Fails Faster Than Humans React**  
AI compounds errors and authority before humans detect patterns. Traditional systems failed slowly; AI crosses undefined boundaries thousands of times before you notice. Ambiguous authority becomes catastrophic delegation at machine speed.  <u>*Set boundaries, validate capability.*</u>

**Ambiguity Is Wisdom**  
Experts navigate gray areas; beginners demand binary answers. AI produces probabilities that demand judgment, not facts that replace it. When systems force ambiguity into yes/no decisions, they destroy the space where expertise operates. <u>*Reveal the probabilities.*</u>

**Build From User Experience**  
Design insight comes from living with the daily friction that analysis misses. People who navigate these daily realities understand what breaks and why. <u>*People wrestling with system failures are the ones qualified to design system futures.*</u>

**Discovery Before Disruption**  
Systems hide logic until something breaks. The redundancy that looks pointless prevents failures you've never seen. The manual step that feels inefficient satisfies requirements nobody documented. Deletion scales faster than comprehension. <u>*Remove only what you understand; build to discover the rest.*</u>

**Reveal the Invisible**  
Gaps in understanding hide inside abstraction until forced into concrete form. The most valuable representation is whatever hurts most to produce; whether diagram, specification, or working prototype. Easy articulation reveals nothing; difficulty exposes confusion. <u>*Choose representations that force confrontation with what you don't know.*</u>

**Iterate Towards What Works**  
Requirements emerge through building, not planning meetings. Inherited practices carry outdated logic that meetings can't expose. Iteration without feedback is repetition; only rapid cycles of making, testing, and failing reveal what actually works. <u>*Build to discover; test to validate; repeat.*</u>

**Scale Only What Earns Its Cost**  
AI compounds small inefficiencies into massive hidden costs. Traditional systems made waste visible; AI makes it invisible until it's catastrophic. Not all complexity delivers value. <u>*Optimize the ratio of value per resource spent.*</u>

**Build for Incremental Obsolescence**  
People naturally want to rebuild legacy systems from scratch rather than break them into replaceable components. Systems built without optionality force catastrophic change when assumptions break. <u>*Enable piece-by-piece evolution, not all-or-nothing replacement.*</u>